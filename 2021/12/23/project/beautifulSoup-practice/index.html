<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>beautifulSoup practice | Ferry's blog</title><meta name="author" content="FerryChan"><meta name="copyright" content="FerryChan"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="本次我采用BeautifulSoup爬取网页数据，并打印到csv文件中，相比于selenium，BeautifulSoup更加快速。 有几个值得注意的问题  编码  find()和find_all()  find()返回指定元素 find_all()返回指定元素的列表  table&#x3D;soup.find(&quot;tbody&quot;).find_all(&quot;tr&quot;)这里先用f">
<meta property="og:type" content="article">
<meta property="og:title" content="beautifulSoup practice">
<meta property="og:url" content="http://ferrychan666.github.io/2021/12/23/project/beautifulSoup-practice/index.html">
<meta property="og:site_name" content="Ferry&#39;s blog">
<meta property="og:description" content="本次我采用BeautifulSoup爬取网页数据，并打印到csv文件中，相比于selenium，BeautifulSoup更加快速。 有几个值得注意的问题  编码  find()和find_all()  find()返回指定元素 find_all()返回指定元素的列表  table&#x3D;soup.find(&quot;tbody&quot;).find_all(&quot;tr&quot;)这里先用f">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://ferrychan666.github.io/img/Tom.jpg">
<meta property="article:published_time" content="2021-12-23T15:20:12.000Z">
<meta property="article:modified_time" content="2022-05-21T17:09:19.000Z">
<meta property="article:author" content="FerryChan">
<meta property="article:tag" content="project">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://ferrychan666.github.io/img/Tom.jpg"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "beautifulSoup practice",
  "url": "http://ferrychan666.github.io/2021/12/23/project/beautifulSoup-practice/",
  "image": "http://ferrychan666.github.io/img/Tom.jpg",
  "datePublished": "2021-12-23T15:20:12.000Z",
  "dateModified": "2022-05-21T17:09:19.000Z",
  "author": [
    {
      "@type": "Person",
      "name": "FerryChan",
      "url": "http://ferrychan666.github.io/"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://ferrychan666.github.io/2021/12/23/project/beautifulSoup-practice/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"top_n_per_article":-1,"unescape":false,"languages":{"hits_empty":"No results found for: ${query}","hits_stats":"${hits} articles found"}},
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":false,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":true},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Failed',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'beautifulSoup practice',
  isHighlightShrink: false,
  isToc: false,
  pageType: 'post'
}</script><meta name="generator" content="Hexo 7.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/Tom.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">155</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">23</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">4</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">Ferry's blog</span></a><a class="nav-page-title" href="/"><span class="site-name">beautifulSoup practice</span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> Search</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">beautifulSoup practice</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2021-12-23T15:20:12.000Z" title="Created 2021-12-23 23:20:12">2021-12-23</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2022-05-21T17:09:19.000Z" title="Updated 2022-05-22 01:09:19">2022-05-22</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post Views:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div><article class="container post-content" id="article-container"><p>本次我采用BeautifulSoup爬取网页数据，并打印到csv文件中，相比于selenium，BeautifulSoup更加快速。</p>
<p>有几个值得注意的问题</p>
<ul>
<li><p>编码</p>
</li>
<li><p>find()和find_all()</p>
<ol>
<li>find()返回指定元素</li>
<li>find_all()返回指定元素的列表</li>
</ol>
<p><code>table=soup.find(&quot;tbody&quot;).find_all(&quot;tr&quot;)</code>这里先用find()找到第一个tbody, 再用find_all()返回tbody中所有的tr元素列表。</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">rankList = []</span><br><span class="line">nameList=[]</span><br><span class="line">regionList=[]</span><br><span class="line">scoreList=[]</span><br><span class="line">regEx=re.<span class="built_in">compile</span>(<span class="string">&quot;ranking.*&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># resquests请求网页</span></span><br><span class="line">url=<span class="string">&#x27;https://www.shanghairanking.cn/rankings/arwu/2021&#x27;</span></span><br><span class="line">res=requests.get(url)</span><br><span class="line"><span class="comment"># 由于BeautifulSoup的原因，不得不用此编码，才不会导致中文乱码</span></span><br><span class="line">res.encoding = res.apparent_encoding</span><br><span class="line"><span class="comment"># 解析网页，返回BeautifulSoup对象</span></span><br><span class="line">soup=BeautifulSoup(res.text,<span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"><span class="comment"># 找到第一个tbody, 再找里面的所有tr，find_all返回元素列表</span></span><br><span class="line">table=soup.find(<span class="string">&quot;tbody&quot;</span>).find_all(<span class="string">&quot;tr&quot;</span>)</span><br><span class="line">i=<span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> table:</span><br><span class="line">    i=i+<span class="number">1</span></span><br><span class="line">    <span class="comment"># find返回元素</span></span><br><span class="line">    rank=item.find(<span class="string">&quot;div&quot;</span>,class_=regEx)</span><br><span class="line">    rankList.append(rank.text.strip())</span><br><span class="line"></span><br><span class="line">    name=item.find(<span class="string">&quot;div&quot;</span>,class_=<span class="string">&quot;link-container&quot;</span>)</span><br><span class="line">    nameList.append(name.text.strip())</span><br><span class="line"></span><br><span class="line">    region=item.select(<span class="string">&quot;#content-box &gt; div.rk-table-box &gt; table &gt; tbody &gt; tr:nth-child(&quot;</span>+<span class="built_in">str</span>(i)+<span class="string">&quot;) &gt; td:nth-child(3)&quot;</span>)</span><br><span class="line">    regionList.append(region[<span class="number">0</span>].text.strip())</span><br><span class="line">    score=item.select(<span class="string">&quot;#content-box &gt; div.rk-table-box &gt; table &gt; tbody &gt; tr:nth-child(&quot;</span>+<span class="built_in">str</span>(i)+<span class="string">&quot;) &gt; td:nth-child(4)&quot;</span>)</span><br><span class="line">    scoreList.append(score[<span class="number">0</span>].text.strip())</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">Data = pd.DataFrame(columns = [<span class="string">&quot;排名&quot;</span>,<span class="string">&quot;名字&quot;</span>,<span class="string">&quot;国家&quot;</span>,<span class="string">&quot;总分&quot;</span>])</span><br><span class="line">Data[<span class="string">&quot;排名&quot;</span>] = rankList</span><br><span class="line">Data[<span class="string">&quot;名字&quot;</span>] = nameList</span><br><span class="line">Data[<span class="string">&quot;国家&quot;</span>] = regionList</span><br><span class="line">Data[<span class="string">&quot;总分&quot;</span>]=scoreList</span><br><span class="line"><span class="comment"># 要导入csv，用此编码，才不会导致中文乱码</span></span><br><span class="line">Data.to_csv(<span class="string">&quot;test.csv&quot;</span>, encoding=<span class="string">&#x27;utf_8_sig&#x27;</span>)<span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">rankList = []</span><br><span class="line">nameList=[]</span><br><span class="line">regionList=[]</span><br><span class="line">scoreList=[]</span><br><span class="line"></span><br><span class="line">regEx=re.<span class="built_in">compile</span>(<span class="string">&quot;ranking.*&quot;</span>)</span><br><span class="line">url=<span class="string">&#x27;https://www.shanghairanking.cn/rankings/arwu/2021&#x27;</span></span><br><span class="line">res=requests.get(url)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 由于BeautifulSoup的原因，不得不用此编码，才不会导致中文乱码</span></span><br><span class="line">res.encoding = res.apparent_encoding</span><br><span class="line"></span><br><span class="line">soup=BeautifulSoup(res.text,<span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line">table=soup.find(<span class="string">&quot;tbody&quot;</span>).find_all(<span class="string">&quot;tr&quot;</span>)</span><br><span class="line">i=<span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> table:</span><br><span class="line">    i=i+<span class="number">1</span></span><br><span class="line">    rank=item.find(<span class="string">&quot;div&quot;</span>,class_=regEx)</span><br><span class="line">    rankList.append(rank.text.strip())</span><br><span class="line"></span><br><span class="line">    name=item.find(<span class="string">&quot;div&quot;</span>,class_=<span class="string">&quot;link-container&quot;</span>)</span><br><span class="line">    nameList.append(name.text.strip())</span><br><span class="line"></span><br><span class="line">    region=item.select(<span class="string">&quot;#content-box &gt; div.rk-table-box &gt; table &gt; tbody &gt; tr:nth-child(&quot;</span>+<span class="built_in">str</span>(i)+<span class="string">&quot;) &gt; td:nth-child(3)&quot;</span>)</span><br><span class="line">    regionList.append(region[<span class="number">0</span>].text.strip())</span><br><span class="line">    score=item.select(<span class="string">&quot;#content-box &gt; div.rk-table-box &gt; table &gt; tbody &gt; tr:nth-child(&quot;</span>+<span class="built_in">str</span>(i)+<span class="string">&quot;) &gt; td:nth-child(4)&quot;</span>)</span><br><span class="line">    scoreList.append(score[<span class="number">0</span>].text.strip())</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">Data = pd.DataFrame(columns = [<span class="string">&quot;排名&quot;</span>,<span class="string">&quot;名字&quot;</span>,<span class="string">&quot;国家&quot;</span>,<span class="string">&quot;总分&quot;</span>])</span><br><span class="line">Data[<span class="string">&quot;排名&quot;</span>] = rankList</span><br><span class="line">Data[<span class="string">&quot;名字&quot;</span>] = nameList</span><br><span class="line">Data[<span class="string">&quot;国家&quot;</span>] = regionList</span><br><span class="line">Data[<span class="string">&quot;总分&quot;</span>]=scoreList</span><br><span class="line"><span class="comment"># 要导入csv，用此编码，才不会导致中文乱码</span></span><br><span class="line">Data.to_csv(<span class="string">&quot;test.csv&quot;</span>, encoding=<span class="string">&#x27;utf_8_sig&#x27;</span>)</span><br></pre></td></tr></table></figure>

</article><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/project/">project</a></div><div class="post-share"><div class="social-share" data-image="/img/Tom.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2021/12/23/Python/BeautifulSoup/" title="BeautifulSoup"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">Previous</div><div class="info-item-2">BeautifulSoup</div></div><div class="info-2"><div class="info-item-1">IntroductionBeautiful Soup is a Python library for pulling data out of HTML and XML files. It works with your favorite parser to provide idiomatic ways of navigating. I’ll be using as an example throughout this document. 123456789101112html_doc = &quot;&quot;&quot;&lt;html&gt;&lt;head&gt;&lt;title&gt;The Dormouse&#x27;s story&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;p class=&quot;title&quot;&gt;&lt;b&gt;The Dormouse&#x27;s story&lt;/b&gt;&lt;/p&gt;&lt;p class=&quot;story&quot;&gt;Once upon...</div></div></div></a><a class="pagination-related" href="/2021/12/24/project/love%20confess/" title="love confess"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">Next</div><div class="info-item-2">love confess</div></div><div class="info-2"><div class="info-item-1">              I once dreamed of a princess like you being mine. Do you love me?   Yessss!   No!        function yes(){       document.getElementById("text").innerHTML="I love you, too. Please feel free to contact me at anytime if further information is needed. My email is ferrychan666@gmail.com.";         var elem = document.getElementById('no');       return elem.parentNode.removeChild(elem);     }     function no() {       document.getElementById("text").innerHTML="I love you because I...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2021/12/24/project/love%20confess/" title="love confess"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2021-12-24</div><div class="info-item-2">love confess</div></div><div class="info-2"><div class="info-item-1">              I once dreamed of a princess like you being mine. Do you love me?   Yessss!   No!        function yes(){       document.getElementById("text").innerHTML="I love you, too. Please feel free to contact me at anytime if further information is needed. My email is ferrychan666@gmail.com.";         var elem = document.getElementById('no');       return elem.parentNode.removeChild(elem);     }     function no() {       document.getElementById("text").innerHTML="I love you because I...</div></div></div></a><a class="pagination-related" href="/2022/01/09/project/%E4%B8%96%E7%95%8C%E5%A4%A7%E5%AD%A6%E6%95%B0%E6%8D%AE%E7%88%AC%E5%8F%96+%E5%8F%AF%E8%A7%86%E5%8C%96/" title="世界大学数据爬取+可视化"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2022-01-09</div><div class="info-item-2">世界大学数据爬取+可视化</div></div><div class="info-2"><div class="info-item-1">数据爬取12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970import reimport pandas as pdfrom selenium import webdriverfrom bs4 import BeautifulSoupfrom selenium.webdriver.common.by import Bydef create_web_driver(url):    # 不打开浏览器的情况下，爬取数据    options=webdriver.ChromeOptions()    # 无头模式    #options.add_argument(&#x27;--headless&#x27;)    # 不加载图片    prefs = &#123;       ...</div></div></div></a><a class="pagination-related" href="/2022/01/06/project/%E4%B8%AD%E5%9B%BD%E5%A4%A7%E5%AD%A6%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/" title="中国大学数据分析"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2022-01-06</div><div class="info-item-2">中国大学数据分析</div></div><div class="info-2"><div class="info-item-1">Selenium效率低的缺点，但有着可见即可爬的优点。BeautifulSoup本来是用于更快地提取html代码中的数据，效率高，但难以爬取动态网页。 所以，我想采取Selenium+BeautifulSoup的方式，高效爬取动态网页。  先selenium经一系列的操作之后，brower.page_source 获取源码 将源码传给BeautifulSoup，快速爬取  下面以中国大学项目作为实例: 12345678910create database collegesdb charset utf8;use collegesdb;create table t(ranking int,name VARCHAR(20),abroad_rate float(10,1),employment_rate float(10,1),numberOfGraduate int,numberOfUndergraduate...</div></div></div></a><a class="pagination-related" href="/2022/01/19/project/%E7%88%AC%E5%8F%96kw%E9%9F%B3%E4%B9%90/" title="爬取kw音乐"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2022-01-19</div><div class="info-item-2">爬取kw音乐</div></div><div class="info-2"><div class="info-item-1"> headers JS逆向  1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950import requestssearchkey=input(&#x27;请输入歌手名字：&#x27;)headers=&#123;    &#x27;Cookie&#x27;: &#x27;kw_token=HJFZGV04WSS&#x27;,    # 主机域名    &#x27;Host&#x27;: &#x27;www.kuwo.cn&#x27;,    # 认证令牌    &#x27;csrf&#x27;: &#x27;HJFZGV04WSS&#x27;,    # 防盗链    &#x27;Referer&#x27;: &#x27;http://www.kuwo.cn/search/list?key=%E5%91%A8%E6%9D%B0%E4%BC%A6&#x27;,    # 浏览器信息    &#x27;User-Agent&#x27;:...</div></div></div></a><a class="pagination-related" href="/2022/01/21/project/%E7%88%AC%E5%8F%96%E5%9B%BE%E7%89%87/" title="爬取图片"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2022-01-21</div><div class="info-item-2">爬取图片</div></div><div class="info-2"><div class="info-item-1">页面滚动由于很多的页面都是动态加载的，在用selenium模拟浏览器时，如果不滚动页面下方，那么有的页面数据就无法加载，所以需要让selenium执行js代码，对页面进行滚动 1234567891011121314def scroll(browser):    # 执行这段代码，会获取到当前窗口总高度    js = &quot;return action=document.body.scrollHeight&quot;    # 初始化现在滚动条所在高度为0    height = 0    # 当前窗口总高度    new_height = browser.execute_script(js)    while height &lt; new_height:        # 将滚动条调整至页面底部        for k in range(height, new_height, 300):            browser.execute_script(&#x27;window.scrollTo(0, &#123;&#125;)&#x27;.format(k))  ...</div></div></div></a><a class="pagination-related" href="/2021/12/09/project/%E8%87%AA%E5%8A%A8%E5%8C%96%E6%92%AD%E6%94%BE%E8%A7%86%E9%A2%91/" title="自动化播放视频"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2021-12-09</div><div class="info-item-2">自动化播放视频</div></div><div class="info-2"><div class="info-item-1">本次我采用Python+selenium写了一个自动播放视频的脚本。 从账号密码登录，切换一个个window，再到切换一层层frame，最终点击播放按钮的过程。  导入包 1234567from selenium import webdriver from selenium.common.exceptions import NoSuchElementExceptionfrom selenium.webdriver.common.by import Byfrom selenium.webdriver.common.keys import Keysfrom selenium.webdriver.support import expected_conditions as ECfrom selenium.webdriver.support.wait import WebDriverWaitimport time  将webdriver静音 1234options =...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/Tom.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">FerryChan</div><div class="author-info-description"></div><div class="site-data"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">155</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">23</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">4</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/FerryChan666"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Posts</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/02/26/vue/vue/" title="vue3 tutorial">vue3 tutorial</a><time datetime="2025-02-26T13:07:23.000Z" title="Created 2025-02-26 21:07:23">2025-02-26</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/02/26/JavaScript/js%20tutorial/" title="js tutorial">js tutorial</a><time datetime="2025-02-26T11:28:20.000Z" title="Created 2025-02-26 19:28:20">2025-02-26</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/02/26/css/css/" title="css tutorial">css tutorial</a><time datetime="2025-02-26T10:08:37.000Z" title="Created 2025-02-26 18:08:37">2025-02-26</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/02/24/Starting-a-Website-with-Django/Starting-a-Website-with-Django/" title="Starting a Website with Django">Starting a Website with Django</a><time datetime="2025-02-24T12:14:10.000Z" title="Created 2025-02-24 20:14:10">2025-02-24</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/02/22/djangotutorial/djangotutorial/" title="Django Tutorial">Django Tutorial</a><time datetime="2025-02-22T07:28:10.000Z" title="Created 2025-02-22 15:28:10">2025-02-22</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Reading Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Toggle Between Light and Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle Between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Settings"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="Back to Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">Search</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  Loading Database</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>